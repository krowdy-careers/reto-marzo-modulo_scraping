# Web Scraping de Productos de Despensa

## **üöÄ Descripci√≥n:**

Este proyecto utiliza Node.js y Express para realizar web scraping y clasificaci√≥n de productos. Para ello, se emplean las siguientes tecnolog√≠as:

- Puppeteer y Puppeteer Cluster: Permiten realizar scraping abriendo m√∫ltiples instancias de navegador en paralelo.

- Hugging Face Inference API: Se usa para clasificar los productos obtenidos en base a sus im√°genes.

- Express: Maneja el servidor y las rutas de la API.

### Endpoints principale:

- `/scrape`: Realiza el scraping de productos.
- `/classify`: Clasifica los productos obtenidos utilizando IA.

## üì¶ Instalaci√≥n

1. Clona el repositorio:
   ```
   git clone https://github.com/tu_usuario/tu_repositorio.git
   ```
2. Instala las dependencias con Yarn:
   ```
   yarn install
   ```
3. Crea un archivo .env y agrega tu API key de Hugging Face:
   ```
   HF_ACCESS_TOKEN=tu_token_aqui
   ```
4. Inicia el servidor:
   ```
   yarn start
   ```

### Endpoints disponibles:

- **GET /** ‚Üí Verifica que el servidor est√° corriendo.
- **GET /scrape** ‚Üí Ejecuta el proceso de scraping.
- **GET /classify** ‚Üí Clasifica los productos obtenidos mediante IA.

## üìå Funcionalidades principales:

- **Scraping con Puppeteer y Puppeteer Cluster**: Obtiene datos de productos mediante m√∫ltiples instancias en paralelo.
- **Clasificaci√≥n con Hugging Face Inference API**: Analiza las im√°genes de los productos y a√±ade un campo de true o false.
- **Servidor con Express**: Expone endpoints para ejecutar las funcionalidades.

## ‚ö†Ô∏è Limitaciones

Este proyecto utiliza la API de **Hugging Face** para la clasificaci√≥n de im√°genes. En su versi√≥n gratuita, el n√∫mero de solicitudes est√° **limitado a 1,000 por d√≠a**.  
Por esta raz√≥n, el an√°lisis de productos est√° **limitado a 500 por defecto**.

## üõ† Tecnolog√≠as

- **Node.js**
- **Express**
- **Puppeteer**
- **Puppeteer Cluster**
- **@huggingface/inference**

## ‚è≥ Tiempo de Procesamiento

El scraping puede tardar un tiempo en completarse porque:

- **Se extraen productos de 24 p√°ginas**, lo que implica m√∫ltiples solicitudes.
- **Las im√°genes deben cargarse completamente** antes de ser analizadas por la IA.
- **Se usa Puppeteer Cluster** para optimizar el tiempo al ejecutar m√∫ltiples instancias en paralelo.

A pesar de estas optimizaciones, el tiempo de espera depender√° de la velocidad de la red y del n√∫mero de productos a procesar.

## üìú Licencia

Este proyecto est√° bajo la licencia MIT. ¬°Si√©ntete libre de contribuir!

---

‚úçÔ∏è **Autor:** [Julia Cruz P√©rez](https://github.com/jjuliacp)
